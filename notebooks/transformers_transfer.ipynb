{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f189f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import mne\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "mne.set_config(\"MNE_DATA\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MNE_DATASETS_BNCI_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MNE_DATASETS_EEGBCI_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MNE_DATASETS_SHIN_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MOABB_RESULTS\", os.path.join(os.getcwd(), \"results\"))\n",
    "os.makedirs(os.environ[\"MNE_DATA\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"MOABB_RESULTS\"], exist_ok=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "from mne.decoding import CSP, PSDEstimator\n",
    "from sklearn.model_selection import KFold\n",
    "from torchmetrics.classification import Accuracy\n",
    "\n",
    "import scripts.transformer.transformer_models as trans\n",
    "from scripts.dataset.eeg_dataset import EEGDataset\n",
    "from scripts.features_extract.welch import extract_welch_features\n",
    "from eeg_logger import logger\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import PhysionetMI\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "\n",
    "moabb.set_log_level(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d63cb6",
   "metadata": {},
   "source": [
    "# Instantiate dataset and load data\n",
    "\n",
    "MOABB makes working with datasets super easy. With Physionet we can specify which runs we want to analyze using `imagined` and `executed` flags. Setting `imagined` to **True** makes `get_data` method return runs 4, 8, 12, 6, 10, 14 because they contain imaginary tasks. For this work, we only need runs 4, 8, 12 because they contain left and right hand movement. The `get_data` method returns dict structured like this:  \n",
    "`data[subject_index][\"session_index\"][\"run_index\"]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15bef32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'0': <RawEDF | S001R04.edf, 65 x 20000 (125.0 s), ~10.0 MiB, data loaded>,\n",
       "  '1': <RawEDF | S001R08.edf, 65 x 20000 (125.0 s), ~10.0 MiB, data loaded>,\n",
       "  '2': <RawEDF | S001R12.edf, 65 x 20000 (125.0 s), ~10.0 MiB, data loaded>,\n",
       "  '3': <RawEDF | S001R06.edf, 65 x 20000 (125.0 s), ~10.0 MiB, data loaded>,\n",
       "  '4': <RawEDF | S001R10.edf, 65 x 20000 (125.0 s), ~10.0 MiB, data loaded>,\n",
       "  '5': <RawEDF | S001R14.edf, 65 x 20000 (125.0 s), ~10.0 MiB, data loaded>}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PhysionetMI(imagined=True, executed=False)\n",
    "subject_list = np.delete(np.arange(1, 110), [87, 91, 99, 103])\n",
    "dataset.subject_list = subject_list\n",
    "epochs_all = []\n",
    "labels_all = []\n",
    "\n",
    "data = dataset.get_data(subjects=subject_list.tolist())\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46d4de",
   "metadata": {},
   "source": [
    "# Extract epochs related to motor imagery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b77f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-08-08 15:11:36,881 - INFO - Event ids: {'left_hand': 1, 'rest': 2, 'right_hand': 3}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def normalize(epochs: mne.Epochs) -> mne.epochs:\n",
    "    \"\"\"\n",
    "    Applies z-score normalization according to this formula:\n",
    "    X* = (X - mean) / std + aN\n",
    "    \"\"\"\n",
    "\n",
    "    data: np.ndarray = epochs.get_data()  # shape: (n_epochs, n_channels, n_times)\n",
    "    mean = data.mean(axis=2, keepdims=True)\n",
    "    std = data.std(axis=2, keepdims=True)\n",
    "    std[std == 0] = 1.0\n",
    "    N = np.random.randn(*data.shape)\n",
    "    a = 0.01\n",
    "\n",
    "    zscored_data = (data - mean) / std + a * N\n",
    "    epochs._data = zscored_data\n",
    "\n",
    "    return epochs\n",
    "\n",
    "\n",
    "selected_event_id = {\"left_hand\": 1, \"right_hand\": 3}  # BASED ON EVENT_IDS\n",
    "tmin_3s, tmax_3s = 2.0, 5.0\n",
    "channels = [\n",
    "    \"FC5\",\n",
    "    \"FC3\",\n",
    "    \"FC1\",\n",
    "    \"FC2\",\n",
    "    \"FC4\",\n",
    "    \"FC6\",\n",
    "    \"C5\",\n",
    "    \"C3\",\n",
    "    \"C1\",\n",
    "    \"Cz\",\n",
    "    \"C2\",\n",
    "    \"C4\",\n",
    "    \"C6\",\n",
    "    \"CP5\",\n",
    "    \"CP3\",\n",
    "    \"CP1\",\n",
    "    \"CP2\",\n",
    "    \"CP4\",\n",
    "    \"CP6\",\n",
    "]\n",
    "epochs_all_subjects = []\n",
    "\n",
    "for subject in subject_list:\n",
    "\n",
    "    session_data = data[subject][\"0\"]\n",
    "    run_4 = session_data[\"0\"]\n",
    "    run_8 = session_data[\"1\"]\n",
    "    run_12 = session_data[\"2\"]\n",
    "\n",
    "    all_runs = mne.concatenate_raws([run_4, run_8, run_12])\n",
    "    events, event_ids = mne.events_from_annotations(all_runs)\n",
    "    if subject == 1:\n",
    "        logger.info(f\"Event ids: {event_ids}\")\n",
    "\n",
    "    epochs_3s = mne.Epochs(\n",
    "        all_runs,\n",
    "        events,\n",
    "        event_id=selected_event_id,\n",
    "        tmin=tmin_3s,\n",
    "        tmax=tmax_3s,\n",
    "        picks=channels,\n",
    "        baseline=None,\n",
    "        preload=True,\n",
    "    )\n",
    "    epochs_3s = normalize(epochs_3s)\n",
    "    epochs_all_subjects.append(epochs_3s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2da96",
   "metadata": {},
   "source": [
    "# Get data and labels from extracted epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc2c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_epochs(epochs: mne.Epochs, label_mapping: dict | None = None) -> tuple[np.ndarray, np.ndarray]:\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, -1]\n",
    "    if label_mapping:\n",
    "        y = np.array([label_mapping[label] for label in y])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_all = []\n",
    "y_all = []\n",
    "for subject_epochs in epochs_all_subjects:\n",
    "    X, y = extract_data_from_epochs(subject_epochs, label_mapping={1: 0, 3: 1})\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "X_all = np.concatenate(X_all)\n",
    "y_all = np.concatenate(y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825af81",
   "metadata": {},
   "source": [
    "# Train and evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532cf19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-08-08 15:12:10,873 - INFO - Training model on gpu\u001b[0m\n",
      "\u001b[34m2025-08-08 15:12:11,135 - INFO - Training SpatialTransformer in fold 1...\u001b[0m\n",
      "\u001b[34m2025-08-08 15:12:46,199 - INFO - Accuracy for SpatialTransformer in fold 1: 67.35%\u001b[0m\n",
      "\u001b[34m2025-08-08 15:12:46,351 - INFO - Training SpatialTransformer in fold 2...\u001b[0m\n",
      "\u001b[34m2025-08-08 15:13:22,221 - INFO - Accuracy for SpatialTransformer in fold 2: 65.87%\u001b[0m\n",
      "\u001b[34m2025-08-08 15:13:22,371 - INFO - Training SpatialTransformer in fold 3...\u001b[0m\n",
      "\u001b[34m2025-08-08 15:13:55,872 - INFO - Accuracy for SpatialTransformer in fold 3: 69.27%\u001b[0m\n",
      "\u001b[34m2025-08-08 15:13:56,005 - INFO - Training SpatialTransformer in fold 4...\u001b[0m\n",
      "\u001b[34m2025-08-08 15:14:31,738 - INFO - Accuracy for SpatialTransformer in fold 4: 64.06%\u001b[0m\n",
      "\u001b[34m2025-08-08 15:14:31,865 - INFO - Training SpatialTransformer in fold 5...\u001b[0m\n",
      "\u001b[34m2025-08-08 15:15:01,782 - INFO - Accuracy for SpatialTransformer in fold 5: 65.87%\u001b[0m\n",
      "\u001b[34m2025-08-08 15:15:01,783 - INFO - Accuracy across 5 folds: 66.49%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def train_model(\n",
    "    model: torch.nn.Module, train_loader: torch.utils.data.DataLoader, device: torch.device, verbose: bool\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0007, weight_decay=0.0001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if verbose:\n",
    "            logger.info(f\"Epoch {epoch+1}/{50}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes accuracy of provided model.\n",
    "\n",
    "    :param model: model to evaluate\n",
    "    :param test_loader: loader for testing data\n",
    "    :param device: device to evaluate model on\n",
    "    \"\"\"\n",
    "    acc = Accuracy(task=\"binary\").to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            acc.update(preds, y_batch)\n",
    "\n",
    "    return acc.compute().item()\n",
    "\n",
    "\n",
    "def train(X, y):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == \"cpu\":\n",
    "        logger.warning(\"Warning - training model on cpu\")\n",
    "    else:\n",
    "        logger.info(\"Training model on gpu\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        train_dataset = EEGDataset(X_train, y_train, cnn_mode=False)\n",
    "        test_dataset = EEGDataset(X_test, y_test, cnn_mode=False)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = trans.SpatialTransformer(input_size=X_train.shape[2], d_model=64, num_heads=8, num_classes=2)\n",
    "\n",
    "        logger.info(f\"Training {model._get_name()} in fold {fold + 1}...\")\n",
    "        train_model(model, train_loader, device, verbose=False)\n",
    "\n",
    "        accuracy = evaluate_model(model, test_loader, device)\n",
    "        logger.info(f\"Accuracy for {model._get_name()} in fold {fold + 1}: {accuracy * 100:.2f}%\")\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    logger.info(f\"Accuracy across 5 folds: {np.mean(accuracies) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "train(X_all, y_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
