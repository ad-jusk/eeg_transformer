{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e5f88e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import mne\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "mne.set_config(\"MNE_DATA\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MNE_DATASETS_BNCI_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MNE_DATASETS_EEGBCI_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MNE_DATASETS_SHIN_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
    "mne.set_config(\"MOABB_RESULTS\", os.path.join(os.getcwd(), \"results\"))\n",
    "os.makedirs(os.environ[\"MNE_DATA\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"MOABB_RESULTS\"], exist_ok=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "from mne.decoding import CSP, PSDEstimator\n",
    "from sklearn.model_selection import KFold\n",
    "from torchmetrics.classification import Accuracy\n",
    "\n",
    "import scripts.transformer.transformer_models as trans\n",
    "from scripts.dataset.eeg_dataset import EEGDataset\n",
    "from scripts.features_extract.welch import extract_welch_features\n",
    "from eeg_logger import logger\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import PhysionetMI\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "\n",
    "moabb.set_log_level(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062afe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PhysionetMI(imagined=True, executed=False)\n",
    "subject_list = np.arange(1, 110, 1)\n",
    "subject_list = np.delete(subject_list, [87, 91, 99, 103])  # THESE SUBJECTS HAVE INCOMPLETE ANNOTATIONS\n",
    "dataset.subject_list = subject_list\n",
    "paradigm = LeftRightImagery(\n",
    "    channels=[\n",
    "        \"FC5\",\n",
    "        \"FC3\",\n",
    "        \"FC1\",\n",
    "        \"C5\",\n",
    "        \"C3\",\n",
    "        \"C1\",\n",
    "        \"CP5\",\n",
    "        \"CP3\",\n",
    "        \"CP1\",\n",
    "        \"FC2\",\n",
    "        \"FC4\",\n",
    "        \"FC6\",\n",
    "        \"C2\",\n",
    "        \"C4\",\n",
    "        \"C6\",\n",
    "        \"CP2\",\n",
    "        \"CP4\",\n",
    "        \"CP6\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75e46b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all, metadata = paradigm.get_data(\n",
    "    dataset, subjects=dataset.subject_list.tolist(), return_epochs=False\n",
    ")  # RETURNS DATA FROM RUNS [4, 8, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36447975",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = metadata[\"subject\"].unique()\n",
    "X = []\n",
    "y = []\n",
    "label_map = {\"left_hand\": 1, \"right_hand\": -1}\n",
    "\n",
    "for idx, subject in enumerate(subjects):\n",
    "\n",
    "    sess_mask = metadata[\"subject\"] == subject\n",
    "    X_sess = X_all[sess_mask]\n",
    "    y_sess = np.array([label_map[label] for label in y_all[sess_mask]])\n",
    "    # TODO: FEATURE EXTRACT\n",
    "    X.append(X_sess)\n",
    "    y.append(y_sess)\n",
    "\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce0c47",
   "metadata": {},
   "source": [
    "# Model training method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bdfa7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-07-23 13:37:34,007 - INFO - Training model on gpu\u001b[0m\n",
      "\u001b[34m2025-07-23 13:37:34,124 - INFO - Training TemporalTransformer in fold 1...\u001b[0m\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target -1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     75\u001b[39m         accuracies.append(accuracy)\n\u001b[32m     77\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMean accuracy across folds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(accuracies)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     68\u001b[39m model = trans.TemporalTransformer(input_size=X_train.shape[\u001b[32m1\u001b[39m], d_model=\u001b[32m64\u001b[39m, num_heads=\u001b[32m8\u001b[39m, num_classes=\u001b[32m2\u001b[39m)\n\u001b[32m     70\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel._get_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m accuracy = evaluate_model(model, test_loader, device)\n\u001b[32m     74\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel._get_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  in fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, device, verbose)\u001b[39m\n\u001b[32m     13\u001b[39m optimizer.zero_grad()\n\u001b[32m     14\u001b[39m output = model(X_batch)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m loss.backward()\n\u001b[32m     17\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\eeg_transformer\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\eeg_transformer\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\eeg_transformer\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1295\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\eeg_transformer\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: Target -1 is out of bounds."
     ]
    }
   ],
   "source": [
    "def train_model(\n",
    "    model: torch.nn.Module, train_loader: torch.utils.data.DataLoader, device: torch.device, verbose: bool\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0007, weight_decay=0.0001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if verbose:\n",
    "            logger.info(f\"Epoch {epoch+1}/{50}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes accuracy of provided model.\n",
    "\n",
    "    :param model: model to evaluate\n",
    "    :param test_loader: loader for testing data\n",
    "    :param device: device to evaluate model on\n",
    "    \"\"\"\n",
    "    acc = Accuracy(task=\"binary\").to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            acc.update(preds, y_batch)\n",
    "\n",
    "    return acc.compute().item()\n",
    "\n",
    "\n",
    "def train(X, y):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == \"cpu\":\n",
    "        logger.warning(\"Warning - training model on cpu\")\n",
    "    else:\n",
    "        logger.info(\"Training model on gpu\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        train_dataset = EEGDataset(X_train, y_train, cnn_mode=False)\n",
    "        test_dataset = EEGDataset(X_test, y_test, cnn_mode=False)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = trans.TemporalTransformer(input_size=X_train.shape[1], d_model=64, num_heads=8, num_classes=2)\n",
    "\n",
    "        logger.info(f\"Training {model._get_name()} in fold {fold + 1}...\")\n",
    "        train_model(model, train_loader, device, verbose=False)\n",
    "\n",
    "        accuracy = evaluate_model(model, test_loader, device)\n",
    "        logger.info(f\"Accuracy for {model._get_name()}  in fold {fold + 1}: {accuracy * 100:.2f}%\")\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    logger.info(f\"Mean accuracy across folds: {np.mean(accuracies):.2f}\")\n",
    "\n",
    "\n",
    "train(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
