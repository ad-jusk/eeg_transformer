{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "795dc64b",
      "metadata": {},
      "source": [
        "# Transfer learning with transformer architecture\n",
        "\n",
        "The purpose of this notebook is to show how finetuning improves the model's accuracy.  \n",
        "Dataset used is Physionet MI. The dataset is split into three subdatasets:\n",
        "\n",
        "- Dataset A (65 subjects)\n",
        "- Dataset B (20 subjects)\n",
        "- Dataset C (20 subjects)\n",
        "\n",
        "Dataset A is used to pretrain the model before finetuning it with dataset B. Dataset C is used for testing.  \n",
        "Comparison is done between two models for each architecture:\n",
        "\n",
        "- one is trained on dataset B and tested with dataset C\n",
        "- second is trained on dataset A, finetuned with dataset B and tested with dataset C\n",
        "\n",
        "Five experimental runs are done for each transformer to calculate mean accuracy of both models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f189f302",
      "metadata": {
        "id": "f189f302"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import mne\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
        "mne.set_config(\"MNE_DATA\", os.path.join(os.getcwd(), \"data\"))\n",
        "mne.set_config(\"MNE_DATASETS_BNCI_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
        "mne.set_config(\"MNE_DATASETS_EEGBCI_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
        "mne.set_config(\"MNE_DATASETS_SHIN_PATH\", os.path.join(os.getcwd(), \"data\"))\n",
        "mne.set_config(\"MOABB_RESULTS\", os.path.join(os.getcwd(), \"results\"))\n",
        "os.makedirs(os.environ[\"MNE_DATA\"], exist_ok=True)\n",
        "os.makedirs(os.environ[\"MOABB_RESULTS\"], exist_ok=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from importlib import reload\n",
        "from mne.decoding import CSP, PSDEstimator\n",
        "from sklearn.model_selection import KFold\n",
        "from torchmetrics.classification import Accuracy\n",
        "from statistics import mean, stdev\n",
        "\n",
        "import scripts.transformer.transformer_models as trans\n",
        "from scripts.dataset.eeg_dataset import EEGDataset\n",
        "from scripts.features_extract.welch import extract_welch_features\n",
        "from eeg_logger import logger\n",
        "\n",
        "import moabb\n",
        "from moabb.datasets import PhysionetMI\n",
        "from moabb.paradigms import LeftRightImagery\n",
        "\n",
        "moabb.set_log_level(\"info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74d63cb6",
      "metadata": {
        "id": "74d63cb6"
      },
      "source": [
        "# Instantiate dataset and load data\n",
        "\n",
        "MOABB makes working with datasets super easy. With Physionet we can specify which runs we want to analyze using `imagined` and `executed` flags. Setting `imagined` to **True** makes `get_data` method return runs 4, 8, 12, 6, 10, 14 because they contain imaginary tasks. For this work, we only need runs 4, 8, 12 because they contain left and right hand movement. The `get_data` method returns dict structured like this:  \n",
        "`data[subject_index][\"session_index\"][\"run_index\"]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "15bef32a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15bef32a",
        "outputId": "c9d832bc-78de-4960-ff52-57225c328bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All subjects: (105,)\n",
            "Big train datset: (65,)\n",
            "Small train dataset: (20,)\n",
            "Test datset: (20,)\n"
          ]
        }
      ],
      "source": [
        "dataset = PhysionetMI(imagined=True, executed=False)\n",
        "subject_list = np.delete(np.arange(1, 110), [87, 91, 99, 103])\n",
        "train_big_subjects = subject_list[:65]\n",
        "train_small_subjects = subject_list[65:85]\n",
        "test_subjects = subject_list[85:]\n",
        "dataset.subject_list = subject_list\n",
        "\n",
        "print(f\"All subjects: {subject_list.shape}\")\n",
        "print(f\"Big train datset: {train_big_subjects.shape}\")\n",
        "print(f\"Small train dataset: {train_small_subjects.shape}\")\n",
        "print(f\"Test datset: {test_subjects.shape}\")\n",
        "\n",
        "train_big_data = dataset.get_data(subjects=train_big_subjects.tolist())\n",
        "train_small_data = dataset.get_data(subjects=train_small_subjects.tolist())\n",
        "test_data = dataset.get_data(subjects=test_subjects.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db46d4de",
      "metadata": {
        "id": "db46d4de"
      },
      "source": [
        "# Extract epochs related to motor imagery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e1b77f35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1b77f35",
        "outputId": "c6be1a0f-8de8-448b-c576-6fbb86f50a7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m2025-08-25 14:33:20,916 - INFO - Event ids: {'left_hand': 1, 'rest': 2, 'right_hand': 3}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def normalize(epochs: mne.Epochs) -> mne.epochs:\n",
        "    \"\"\"\n",
        "    Applies z-score normalization according to this formula:\n",
        "    X* = (X - mean) / std + aN\n",
        "    \"\"\"\n",
        "\n",
        "    data: np.ndarray = epochs.get_data()  # shape: (n_epochs, n_channels, n_times)\n",
        "    mean = data.mean(axis=2, keepdims=True)\n",
        "    std = data.std(axis=2, keepdims=True)\n",
        "    std[std == 0] = 1.0\n",
        "    N = np.random.randn(*data.shape)\n",
        "    a = 0.01\n",
        "\n",
        "    zscored_data = (data - mean) / std + a * N\n",
        "    epochs._data = zscored_data\n",
        "\n",
        "    return epochs\n",
        "\n",
        "\n",
        "selected_event_id = {\"left_hand\": 1, \"right_hand\": 3}  # BASED ON EVENT_IDS\n",
        "tmin_3s, tmax_3s = 2.0, 5.0\n",
        "channels = [\n",
        "    \"FC5\",\n",
        "    \"FC3\",\n",
        "    \"FC1\",\n",
        "    \"FC2\",\n",
        "    \"FC4\",\n",
        "    \"FC6\",\n",
        "    \"C5\",\n",
        "    \"C3\",\n",
        "    \"C1\",\n",
        "    \"Cz\",\n",
        "    \"C2\",\n",
        "    \"C4\",\n",
        "    \"C6\",\n",
        "    \"CP5\",\n",
        "    \"CP3\",\n",
        "    \"CP1\",\n",
        "    \"CP2\",\n",
        "    \"CP4\",\n",
        "    \"CP6\",\n",
        "]\n",
        "epochs_big_dataset = []\n",
        "epochs_small_dataset = []\n",
        "epochs_test_dataset = []\n",
        "\n",
        "for subject in subject_list:\n",
        "    session_data = None\n",
        "\n",
        "    if subject in train_big_subjects:\n",
        "        session_data = train_big_data[subject][\"0\"]\n",
        "    elif subject in train_small_subjects:\n",
        "        session_data = train_small_data[subject][\"0\"]\n",
        "    elif subject in test_subjects:\n",
        "        session_data = test_data[subject][\"0\"]\n",
        "    else:\n",
        "        logger.error(f\"Subject {subject} does not belong to any dataset\")\n",
        "\n",
        "    run_4 = session_data[\"0\"]\n",
        "    run_8 = session_data[\"1\"]\n",
        "    run_12 = session_data[\"2\"]\n",
        "\n",
        "    all_runs = mne.concatenate_raws([run_4, run_8, run_12])\n",
        "    events, event_ids = mne.events_from_annotations(all_runs)\n",
        "    if subject == 1:\n",
        "        logger.info(f\"Event ids: {event_ids}\")\n",
        "\n",
        "    epochs_3s = mne.Epochs(\n",
        "        all_runs,\n",
        "        events,\n",
        "        event_id=selected_event_id,\n",
        "        tmin=tmin_3s,\n",
        "        tmax=tmax_3s,\n",
        "        picks=channels,\n",
        "        baseline=None,\n",
        "        preload=True,\n",
        "    )\n",
        "    epochs_3s = normalize(epochs_3s)\n",
        "\n",
        "    if subject in train_big_subjects:\n",
        "        epochs_big_dataset.append(epochs_3s)\n",
        "    elif subject in train_small_subjects:\n",
        "        epochs_small_dataset.append(epochs_3s)\n",
        "    elif subject in test_subjects:\n",
        "        epochs_test_dataset.append(epochs_3s)\n",
        "    else:\n",
        "        logger.error(f\"Subject {subject} does not belong to any dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c2da96",
      "metadata": {
        "id": "c1c2da96"
      },
      "source": [
        "# Get data and labels from extracted epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ecc2c282",
      "metadata": {
        "id": "ecc2c282"
      },
      "outputs": [],
      "source": [
        "def extract_data_from_epochs(epochs: mne.Epochs, label_mapping: dict | None = None) -> tuple[np.ndarray, np.ndarray]:\n",
        "    X = epochs.get_data()\n",
        "    y = epochs.events[:, -1]\n",
        "    if label_mapping:\n",
        "        y = np.array([label_mapping[label] for label in y])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X_big_train = []\n",
        "y_big_train = []\n",
        "\n",
        "X_small_train = []\n",
        "y_small_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for epochs in epochs_big_dataset:\n",
        "    X, y = extract_data_from_epochs(epochs, label_mapping={1: 0, 3: 1})\n",
        "    X_big_train.append(X)\n",
        "    y_big_train.append(y)\n",
        "for epochs in epochs_small_dataset:\n",
        "    X, y = extract_data_from_epochs(epochs, label_mapping={1: 0, 3: 1})\n",
        "    X_small_train.append(X)\n",
        "    y_small_train.append(y)\n",
        "for epochs in epochs_test_dataset:\n",
        "    X, y = extract_data_from_epochs(epochs, label_mapping={1: 0, 3: 1})\n",
        "    X_test.append(X)\n",
        "    y_test.append(y)\n",
        "\n",
        "X_big_train = np.concatenate(X_big_train)\n",
        "y_big_train = np.concatenate(y_big_train)\n",
        "X_small_train = np.concatenate(X_small_train)\n",
        "y_small_train = np.concatenate(y_small_train)\n",
        "X_test = np.concatenate(X_test)\n",
        "y_test = np.concatenate(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9825af81",
      "metadata": {
        "id": "9825af81"
      },
      "source": [
        "# Train and evaluate methods\n",
        "\n",
        "Here methods for testing and evaluating models are defined. The purpose of this work is to show how finetuning improves accuracy. Five different transformer models are tested.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "532cf19b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "532cf19b",
        "outputId": "562fc4a9-b3b5-4f4d-f1f6-ba6483da6bc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m2025-08-25 15:26:24,873 - INFO - Training will be done on gpu\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from enum import Enum\n",
        "\n",
        "\n",
        "class ModelType(Enum):\n",
        "    SPATIAL = 1\n",
        "    TEMPORAL = 2\n",
        "    SPATIAL_CNN = 3\n",
        "    TEMPORAL_CNN = 4\n",
        "    FUSION_CNN = 5\n",
        "\n",
        "\n",
        "def __is_cnn(model_type: ModelType) -> bool:\n",
        "    return model_type in [ModelType.SPATIAL_CNN, ModelType.TEMPORAL_CNN, ModelType.FUSION_CNN]\n",
        "\n",
        "\n",
        "def __train_model(\n",
        "    model: torch.nn.Module,\n",
        "    train_loader: torch.utils.data.DataLoader,\n",
        "    device: torch.device,\n",
        "    epochs: int = 50,\n",
        "    lr: float = 0.0007,\n",
        "    weight_decay=0.0001,\n",
        "    verbose: bool = False,\n",
        ") -> torch.nn.Module:\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        if verbose:\n",
        "            logger.info(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model_type: ModelType,\n",
        "    device: torch.device,\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_finetune: np.ndarray = None,\n",
        "    y_finetune: np.ndarray = None,\n",
        ") -> tuple[torch.nn.Module, bool]:\n",
        "\n",
        "    cnn_mode = __is_cnn(model_type)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        EEGDataset(X_train, y_train, cnn_mode=cnn_mode),\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    model = None\n",
        "    match (model_type):\n",
        "        case ModelType.SPATIAL:\n",
        "            model = trans.SpatialTransformer(input_size=X_train.shape[2], d_model=64, num_heads=8, num_classes=2)\n",
        "        case ModelType.TEMPORAL:\n",
        "            model = trans.TemporalTransformer(input_size=X_train.shape[1], d_model=64, num_heads=8, num_classes=2)\n",
        "        case ModelType.SPATIAL_CNN:\n",
        "            model = trans.SpatialCNNTransformer(d_model=64, num_heads=8, num_classes=2)\n",
        "        case ModelType.TEMPORAL_CNN:\n",
        "            model = trans.TemporalCNNTransformer(d_model=64, num_heads=8, num_classes=2)\n",
        "        case ModelType.FUSION_CNN:\n",
        "            model = trans.FusionCNNTransformer(d_model=64, num_heads=8, num_classes=2)\n",
        "        case _:\n",
        "            logger.error(\"Wrong model type!\")\n",
        "            return\n",
        "\n",
        "    __train_model(model, train_loader, device, epochs=50)\n",
        "\n",
        "    if X_finetune is not None and y_finetune is not None:\n",
        "        train_loader_ft = torch.utils.data.DataLoader(\n",
        "            EEGDataset(X_finetune, y_finetune, cnn_mode=cnn_mode), batch_size=32, shuffle=True\n",
        "        )\n",
        "        __train_model(model, train_loader_ft, device, epochs=5, lr=1e-5, weight_decay=0)\n",
        "\n",
        "    return model, cnn_mode\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model: torch.nn.Module, device: torch.device, cnn_mode: bool, X_test: np.ndarray, y_test: np.ndarray\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Computes accuracy of provided model.\n",
        "    \"\"\"\n",
        "    acc = Accuracy(task=\"binary\").to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        EEGDataset(X_test, y_test, cnn_mode=cnn_mode), batch_size=32, shuffle=True\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            output = model(X_batch)\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            acc.update(preds, y_batch)\n",
        "\n",
        "    return acc.compute().item()\n",
        "\n",
        "\n",
        "runs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == \"cpu\":\n",
        "    logger.warning(\"Warning - training will be done on cpu\")\n",
        "else:\n",
        "    logger.info(\"Training will be done on gpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3d6cdb1",
      "metadata": {
        "id": "d3d6cdb1"
      },
      "source": [
        "# Training and evaluating Spatial transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1d9fdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a1d9fdd",
        "outputId": "d2ecd185-bf74-4201-a140-5f6edb50ec22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m2025-08-25 15:27:16,357 - INFO - Run 1/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:27:28,307 - INFO - Accuracy for SpatialTransformer without finetuning: 56.55%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:28:08,972 - INFO - Accuracy for SpatialTransformer with finetuning: 63.93%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:28:08,975 - INFO - Run 2/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:28:20,891 - INFO - Accuracy for SpatialTransformer without finetuning: 58.69%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:29:00,876 - INFO - Accuracy for SpatialTransformer with finetuning: 62.74%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:29:00,879 - INFO - Run 3/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:29:13,099 - INFO - Accuracy for SpatialTransformer without finetuning: 57.62%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:29:53,572 - INFO - Accuracy for SpatialTransformer with finetuning: 62.50%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:29:53,573 - INFO - Run 4/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:30:05,437 - INFO - Accuracy for SpatialTransformer without finetuning: 57.38%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:30:45,456 - INFO - Accuracy for SpatialTransformer with finetuning: 64.40%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:30:45,458 - INFO - Run 5/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:30:57,670 - INFO - Accuracy for SpatialTransformer without finetuning: 56.19%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:31:37,617 - INFO - Accuracy for SpatialTransformer with finetuning: 62.98%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:31:37,620 - INFO - Mean accuracy over 5 runs without finetuning: 57.29% +- 0.98%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:31:37,621 - INFO - Mean accuracy over 5 runs with finetuning: 63.31% +- 0.82%\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "accuracies_no_finetune = []\n",
        "accuracies_finetune = []\n",
        "model_type = ModelType.SPATIAL\n",
        "\n",
        "for run in range(runs):\n",
        "\n",
        "    logger.info(f\"Run {run+1}/{runs}\")\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} without finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_no_finetune.append(accuracy)\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_big_train, y_big_train, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} with finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_finetune.append(accuracy)\n",
        "\n",
        "acc_mean_no_finetune = mean(accuracies_no_finetune)\n",
        "std_no_finetune = stdev(accuracies_no_finetune)\n",
        "acc_mean_finetune = mean(accuracies_finetune)\n",
        "std_finetune = stdev(accuracies_finetune)\n",
        "\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs without finetuning: {acc_mean_no_finetune * 100:.2f}% +- {std_no_finetune * 100:.2f}%\"\n",
        ")\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs with finetuning: {acc_mean_finetune * 100:.2f}% +- {std_finetune * 100:.2f}%\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ZjMHKGOp4LP",
      "metadata": {
        "id": "1ZjMHKGOp4LP"
      },
      "source": [
        "# Training and evaluating Temporal Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k6zj-MIMp8oQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6zj-MIMp8oQ",
        "outputId": "e65dedeb-5065-43a9-b9d1-a0212adeba70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m2025-08-25 16:07:06,216 - INFO - Run 1/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:08:47,212 - INFO - Accuracy for TemporalTransformer without finetuning: 66.43%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:14:21,582 - INFO - Accuracy for TemporalTransformer with finetuning: 68.45%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:14:21,583 - INFO - Run 2/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:16:01,918 - INFO - Accuracy for TemporalTransformer without finetuning: 63.93%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:21:36,950 - INFO - Accuracy for TemporalTransformer with finetuning: 65.71%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:21:36,952 - INFO - Run 3/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:23:17,467 - INFO - Accuracy for TemporalTransformer without finetuning: 64.88%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:28:52,834 - INFO - Accuracy for TemporalTransformer with finetuning: 66.67%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:28:52,838 - INFO - Run 4/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:30:33,416 - INFO - Accuracy for TemporalTransformer without finetuning: 64.52%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:36:08,744 - INFO - Accuracy for TemporalTransformer with finetuning: 67.02%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:36:08,746 - INFO - Run 5/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:37:49,259 - INFO - Accuracy for TemporalTransformer without finetuning: 66.67%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:43:24,438 - INFO - Accuracy for TemporalTransformer with finetuning: 67.14%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:43:24,441 - INFO - Mean accuracy over 5 runs without finetuning: 65.29% +- 1.20%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:43:24,442 - INFO - Mean accuracy over 5 runs with finetuning: 67.00% +- 0.99%\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "accuracies_no_finetune = []\n",
        "accuracies_finetune = []\n",
        "model_type = ModelType.TEMPORAL\n",
        "\n",
        "for run in range(runs):\n",
        "\n",
        "    logger.info(f\"Run {run+1}/{runs}\")\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} without finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_no_finetune.append(accuracy)\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_big_train, y_big_train, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} with finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_finetune.append(accuracy)\n",
        "\n",
        "acc_mean_no_finetune = mean(accuracies_no_finetune)\n",
        "std_no_finetune = stdev(accuracies_no_finetune)\n",
        "acc_mean_finetune = mean(accuracies_finetune)\n",
        "std_finetune = stdev(accuracies_finetune)\n",
        "\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs without finetuning: {acc_mean_no_finetune * 100:.2f}% +- {std_no_finetune * 100:.2f}%\"\n",
        ")\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs with finetuning: {acc_mean_finetune * 100:.2f}% +- {std_finetune * 100:.2f}%\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SH3WpTB4sWU_",
      "metadata": {
        "id": "SH3WpTB4sWU_"
      },
      "source": [
        "# Training and evaluating SpatialCNN transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kc7_2BTQsaze",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc7_2BTQsaze",
        "outputId": "79d4880f-143b-439a-8b1d-12da4c2f13da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m2025-08-25 16:00:16,290 - INFO - Run 1/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:00:32,900 - INFO - Accuracy for SpatialCNNTransformer without finetuning: 61.79%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:01:27,665 - INFO - Accuracy for SpatialCNNTransformer with finetuning: 66.43%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:01:27,666 - INFO - Run 2/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:01:44,458 - INFO - Accuracy for SpatialCNNTransformer without finetuning: 62.26%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:02:38,248 - INFO - Accuracy for SpatialCNNTransformer with finetuning: 66.19%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:02:38,250 - INFO - Run 3/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:02:54,325 - INFO - Accuracy for SpatialCNNTransformer without finetuning: 61.79%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:03:48,036 - INFO - Accuracy for SpatialCNNTransformer with finetuning: 68.10%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:03:48,038 - INFO - Run 4/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:04:04,561 - INFO - Accuracy for SpatialCNNTransformer without finetuning: 62.62%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:04:58,553 - INFO - Accuracy for SpatialCNNTransformer with finetuning: 65.71%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:04:58,555 - INFO - Run 5/5\u001b[0m\n",
            "\u001b[34m2025-08-25 16:05:14,708 - INFO - Accuracy for SpatialCNNTransformer without finetuning: 63.57%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:06:08,475 - INFO - Accuracy for SpatialCNNTransformer with finetuning: 68.69%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:06:08,477 - INFO - Mean accuracy over 5 runs without finetuning: 62.40% +- 0.74%\u001b[0m\n",
            "\u001b[34m2025-08-25 16:06:08,478 - INFO - Mean accuracy over 5 runs with finetuning: 67.02% +- 1.29%\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "accuracies_no_finetune = []\n",
        "accuracies_finetune = []\n",
        "model_type = ModelType.SPATIAL_CNN\n",
        "\n",
        "for run in range(runs):\n",
        "\n",
        "    logger.info(f\"Run {run+1}/{runs}\")\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} without finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_no_finetune.append(accuracy)\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_big_train, y_big_train, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} with finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_finetune.append(accuracy)\n",
        "\n",
        "acc_mean_no_finetune = mean(accuracies_no_finetune)\n",
        "std_no_finetune = stdev(accuracies_no_finetune)\n",
        "acc_mean_finetune = mean(accuracies_finetune)\n",
        "std_finetune = stdev(accuracies_finetune)\n",
        "\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs without finetuning: {acc_mean_no_finetune * 100:.2f}% +- {std_no_finetune * 100:.2f}%\"\n",
        ")\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs with finetuning: {acc_mean_finetune * 100:.2f}% +- {std_finetune * 100:.2f}%\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pQBy7U1Ts1CG",
      "metadata": {
        "id": "pQBy7U1Ts1CG"
      },
      "source": [
        "# Training and evaluating TemporalCNN transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F1k4BFAMs3MV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1k4BFAMs3MV",
        "outputId": "d35c7f10-ab89-412e-f3ae-df158e57ed06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m2025-08-25 15:41:19,681 - INFO - Run 1/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:41:36,726 - INFO - Accuracy for TemporalCNNTransformer without finetuning: 57.14%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:42:33,519 - INFO - Accuracy for TemporalCNNTransformer with finetuning: 64.29%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:42:33,523 - INFO - Run 2/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:42:50,481 - INFO - Accuracy for TemporalCNNTransformer without finetuning: 61.67%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:43:46,581 - INFO - Accuracy for TemporalCNNTransformer with finetuning: 64.88%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:43:46,582 - INFO - Run 3/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:44:03,827 - INFO - Accuracy for TemporalCNNTransformer without finetuning: 55.95%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:45:00,180 - INFO - Accuracy for TemporalCNNTransformer with finetuning: 66.79%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:45:00,182 - INFO - Run 4/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:45:17,095 - INFO - Accuracy for TemporalCNNTransformer without finetuning: 59.52%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:46:13,758 - INFO - Accuracy for TemporalCNNTransformer with finetuning: 64.76%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:46:13,761 - INFO - Run 5/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:46:30,709 - INFO - Accuracy for TemporalCNNTransformer without finetuning: 58.81%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:47:26,686 - INFO - Accuracy for TemporalCNNTransformer with finetuning: 66.07%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:47:26,688 - INFO - Mean accuracy over 5 runs without finetuning: 58.62% +- 2.20%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:47:26,690 - INFO - Mean accuracy over 5 runs with finetuning: 65.36% +- 1.03%\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "accuracies_no_finetune = []\n",
        "accuracies_finetune = []\n",
        "model_type = ModelType.TEMPORAL_CNN\n",
        "\n",
        "for run in range(runs):\n",
        "\n",
        "    logger.info(f\"Run {run+1}/{runs}\")\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} without finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_no_finetune.append(accuracy)\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_big_train, y_big_train, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} with finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_finetune.append(accuracy)\n",
        "\n",
        "acc_mean_no_finetune = mean(accuracies_no_finetune)\n",
        "std_no_finetune = stdev(accuracies_no_finetune)\n",
        "acc_mean_finetune = mean(accuracies_finetune)\n",
        "std_finetune = stdev(accuracies_finetune)\n",
        "\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs without finetuning: {acc_mean_no_finetune * 100:.2f}% +- {std_no_finetune * 100:.2f}%\"\n",
        ")\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs with finetuning: {acc_mean_finetune * 100:.2f}% +- {std_finetune * 100:.2f}%\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gc7vZLV3tbYW",
      "metadata": {
        "id": "Gc7vZLV3tbYW"
      },
      "source": [
        "# Training and evaluating FusionCNN transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SxhnTQRwtdX2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxhnTQRwtdX2",
        "outputId": "a5c35f27-27f4-41ba-98f1-f80d239a55a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m2025-08-25 15:47:37,710 - INFO - Run 1/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:48:06,606 - INFO - Accuracy for FusionCNNTransformer without finetuning: 61.31%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:49:41,873 - INFO - Accuracy for FusionCNNTransformer with finetuning: 64.52%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:49:41,874 - INFO - Run 2/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:50:10,574 - INFO - Accuracy for FusionCNNTransformer without finetuning: 61.90%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:51:45,258 - INFO - Accuracy for FusionCNNTransformer with finetuning: 66.07%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:51:45,260 - INFO - Run 3/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:52:14,348 - INFO - Accuracy for FusionCNNTransformer without finetuning: 61.19%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:53:48,967 - INFO - Accuracy for FusionCNNTransformer with finetuning: 67.38%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:53:48,969 - INFO - Run 4/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:54:17,733 - INFO - Accuracy for FusionCNNTransformer without finetuning: 60.95%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:55:52,736 - INFO - Accuracy for FusionCNNTransformer with finetuning: 65.95%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:55:52,739 - INFO - Run 5/5\u001b[0m\n",
            "\u001b[34m2025-08-25 15:56:21,838 - INFO - Accuracy for FusionCNNTransformer without finetuning: 62.26%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:57:56,574 - INFO - Accuracy for FusionCNNTransformer with finetuning: 67.26%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:57:56,577 - INFO - Mean accuracy over 5 runs without finetuning: 61.52% +- 0.54%\u001b[0m\n",
            "\u001b[34m2025-08-25 15:57:56,579 - INFO - Mean accuracy over 5 runs with finetuning: 66.24% +- 1.16%\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "accuracies_no_finetune = []\n",
        "accuracies_finetune = []\n",
        "model_type = ModelType.FUSION_CNN\n",
        "\n",
        "for run in range(runs):\n",
        "\n",
        "    logger.info(f\"Run {run+1}/{runs}\")\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} without finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_no_finetune.append(accuracy)\n",
        "\n",
        "    model, cnn_mode = train_model(model_type, device, X_big_train, y_big_train, X_small_train, y_small_train)\n",
        "    accuracy = evaluate_model(model, device, cnn_mode, X_test, y_test)\n",
        "\n",
        "    logger.info(f\"Accuracy for {model._get_name()} with finetuning: {accuracy * 100:.2f}%\")\n",
        "    accuracies_finetune.append(accuracy)\n",
        "\n",
        "acc_mean_no_finetune = mean(accuracies_no_finetune)\n",
        "std_no_finetune = stdev(accuracies_no_finetune)\n",
        "acc_mean_finetune = mean(accuracies_finetune)\n",
        "std_finetune = stdev(accuracies_finetune)\n",
        "\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs without finetuning: {acc_mean_no_finetune * 100:.2f}% +- {std_no_finetune * 100:.2f}%\"\n",
        ")\n",
        "logger.info(\n",
        "    f\"Mean accuracy over {runs} runs with finetuning: {acc_mean_finetune * 100:.2f}% +- {std_finetune * 100:.2f}%\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
